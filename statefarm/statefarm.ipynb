{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# This notebook is the joint work of Joseph Palermo and Alok Singh"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Using Theano backend.\n",
      "WARNING (theano.sandbox.cuda): The cuda backend is deprecated and will be removed in the next release (v0.10).  Please switch to the gpuarray backend. You can get more information about how to switch at this URL:\n",
      " https://github.com/Theano/Theano/wiki/Converting-to-the-new-gpu-back-end%28gpuarray%29\n",
      "\n",
      "Using gpu device 0: Tesla K80 (CNMeM is disabled, cuDNN 5103)\n"
     ]
    }
   ],
   "source": [
    "import keras\n",
    "from keras import backend as K\n",
    "from keras.utils.data_utils import get_file\n",
    "from keras.utils import np_utils\n",
    "from keras.utils.np_utils import to_categorical\n",
    "from keras.models import Sequential, Model\n",
    "from keras.layers import Activation, Dense, Dropout, Input\n",
    "from keras.layers import TimeDistributed, Activation, SimpleRNN, GRU\n",
    "from keras.layers.core import Flatten, Dense, Dropout, Lambda\n",
    "from keras.regularizers import l2, l1\n",
    "from keras.layers.normalization import BatchNormalization\n",
    "from keras.optimizers import SGD, RMSprop, Adam\n",
    "from keras.metrics import categorical_crossentropy, categorical_accuracy\n",
    "from keras.layers.convolutional import *\n",
    "from keras.preprocessing import image, sequence\n",
    "from keras.preprocessing.text import Tokenizer\n",
    "from keras.callbacks import EarlyStopping, CSVLogger\n",
    "\n",
    "from os.path import abspath, expanduser\n",
    "import numpy as np\n",
    "import pandas\n",
    "import bcolz\n",
    "import PIL\n",
    "from PIL import Image\n",
    "from matplotlib import pyplot as plt\n",
    "%matplotlib inline\n",
    "\n",
    "import random\n",
    "from shutil import move, copy"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "# utilities\n",
    "\n",
    "def save_array(fname, arr): \n",
    "    c=bcolz.carray(arr, rootdir=fname, mode='w')\n",
    "    c.flush()\n",
    "    \n",
    "def load_array(fname):\n",
    "    return bcolz.open(fname)\n",
    "\n",
    "def get_raw_batches(batch_gen, batch_size, n_epochs):\n",
    "    img_batches = []\n",
    "    n_batches = n_epochs * batch_gen.samples // batch_size\n",
    "    print(n_batches)\n",
    "    for i in range(n_batches):\n",
    "        if i % 10 == 0:\n",
    "            print(i)\n",
    "        batch = batch_gen.next()\n",
    "        img_batches.append(batch[0])\n",
    "    return np.concatenate(img_batches)\n",
    "\n",
    "def plots(ims, figsize=(24,12), rows=1, interp=False, titles=None):\n",
    "    if type(ims[0]) is np.ndarray:\n",
    "        ims = np.array(ims).astype(np.uint8)\n",
    "        if (ims.shape[-1] != 3):\n",
    "            ims = ims.transpose((0,2,3,1))\n",
    "    f = plt.figure(figsize=figsize)\n",
    "    cols = len(ims)//rows if len(ims) % 2 == 0 else len(ims)//rows + 1\n",
    "    for i in range(len(ims)):\n",
    "        sp = f.add_subplot(rows, cols, i+1)\n",
    "        sp.axis('Off')\n",
    "        if titles is not None:\n",
    "            sp.set_title(titles[i], fontsize=16)\n",
    "        plt.imshow(ims[i], interpolation=None if interp else 'none')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Data Preprocessing"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "# 1 - create a validation set consisting of different drivers than are in the training set\n",
    "\n",
    "data_path = \"data/statefarm/\"\n",
    "driver_data = pandas.read_csv(data_path+\"driver_imgs_list.csv\")\n",
    "unique_subjects = driver_data[\"subject\"].unique() # 26 unique subjects\n",
    "subjects = driver_data[\"subject\"].tolist()\n",
    "classes = driver_data[\"classname\"].tolist()\n",
    "imgs = driver_data[\"img\"].tolist()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# get random sample of unique_subjects\n",
    "validation_subjects = np.random.choice(unique_subjects, size=4, replace=False) # select 4 without replacement\n",
    "train_subjects = [subj for subj in unique_subjects if subj not in validation_subjects]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "# construct a dictionary that maps each classname to a list of picture ids in which the subject in the picture is in\n",
    "# validation_subjects\n",
    "subject_mapping = {c: [] for c in driver_data[\"classname\"].unique()}\n",
    "for i, subj in enumerate(subjects):\n",
    "    if subj in validation_subjects:\n",
    "        subject_mapping[classes[i]].append(imgs[i])   "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "# inspect the distribution of classes in the validation set\n",
    "print(validation_subjects)\n",
    "print(len(subject_mapping['c0']))\n",
    "print(len(subject_mapping['c1']))\n",
    "print(len(subject_mapping['c2']))\n",
    "print(len(subject_mapping['c3']))\n",
    "print(len(subject_mapping['c4']))\n",
    "print(len(subject_mapping['c5']))\n",
    "print(len(subject_mapping['c6']))\n",
    "print(len(subject_mapping['c7']))\n",
    "print(len(subject_mapping['c8']))\n",
    "print(len(subject_mapping['c9']))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "# use the constructed dictionary to selectively move files to the validation set\n",
    "\n",
    "# %cd ~/nbs/data/statefarm\n",
    "# for classname in subject_mapping:\n",
    "#     train_classpath = \"train/\" + classname + \"/\"\n",
    "#     valid_classpath = \"valid/\" + classname + \"/\"\n",
    "#     for filename in subject_mapping[classname]:\n",
    "#         move(train_classpath + filename, valid_classpath + filename)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "# 2 - construct sample data by the same method\n",
    "\n",
    "# construct sample training data\n",
    "sample_train = np.random.choice(train_subjects, size=2, replace=False) # select 2 without replacement\n",
    "train_subject_mapping = {c: [] for c in driver_data[\"classname\"].unique()}\n",
    "for i, subj in enumerate(subjects):\n",
    "    if subj in sample_train:\n",
    "        train_subject_mapping[classes[i]].append(imgs[i]) "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "# construct sample validation data\n",
    "sample_valid = np.random.choice(validation_subjects, size=1, replace=False) # select 1 without replacement\n",
    "valid_subject_mapping = {c: [] for c in driver_data[\"classname\"].unique()}\n",
    "for i, subj in enumerate(subjects):\n",
    "    if subj in sample_valid:\n",
    "        valid_subject_mapping[classes[i]].append(imgs[i])     "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "# actually copy the sample training data\n",
    "\n",
    "# %cd ~/nbs/data/statefarm\n",
    "# for classname in train_subject_mapping:\n",
    "#     train_path = \"train/\" + classname + \"/\"\n",
    "#     sample_path = \"sample/train/\" + classname + \"/\"\n",
    "#     for filename in train_subject_mapping[classname]:\n",
    "#         copy(train_path + filename, sample_path + filename)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "# actually copy the sample validation data\n",
    "\n",
    "# %cd ~/nbs/data/statefarm\n",
    "# for classname in valid_subject_mapping:\n",
    "#     valid_path = \"valid/\" + classname + \"/\"\n",
    "#     sample_path = \"sample/valid/\" + classname + \"/\"\n",
    "#     for filename in valid_subject_mapping[classname]:\n",
    "#         copy(valid_path + filename, sample_path + filename)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Train some models"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 1 - simple conv net"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "def simple_conv(batch_gen, val_batch_gen):\n",
    "    model = Sequential([\n",
    "            BatchNormalization(axis=1, input_shape=(224,224,3)),\n",
    "            Convolution2D(32,(3,3), activation='relu'),\n",
    "            BatchNormalization(axis=1),\n",
    "            MaxPooling2D((3,3)),\n",
    "            Convolution2D(64,(3,3), activation='relu'),\n",
    "            BatchNormalization(axis=1),\n",
    "            MaxPooling2D((3,3)),\n",
    "            Flatten(),\n",
    "            Dense(200, activation='relu'),\n",
    "            BatchNormalization(),\n",
    "            Dense(10, activation='softmax')\n",
    "        ])\n",
    "    model.compile(Adam(lr=1e-4), loss='categorical_crossentropy', metrics=['accuracy'])\n",
    "    model.fit_generator(batch_gen, batch_gen.samples//batch_size, epochs=2, validation_data=val_batch_gen, validation_steps=val_batch_gen.samples//batch_size)\n",
    "    model.optimizer.lr = 1e-3\n",
    "    model.fit_generator(batch_gen, val_batch_gen.samples//batch_size, epochs=4, validation_data=val_batch_gen, validation_steps=val_batch_gen.samples//batch_size)\n",
    "    return model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "%cd ~/nbs\n",
    "batch_size = 128\n",
    "data_path = \"data/statefarm/\"\n",
    "gen = image.ImageDataGenerator()\n",
    "batch_gen = gen.flow_from_directory(data_path+\"train\", batch_size=batch_size, target_size=(224, 224))\n",
    "val_batch_gen = gen.flow_from_directory(data_path+\"valid\", batch_size=batch_size, target_size=(224, 224))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "model = simple_conv(batch_gen, val_batch_gen)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "# the previous training overfits so try adding data augmentation \n",
    "gen = image.ImageDataGenerator(rotation_range=15, height_shift_range=0.05, shear_range=0.1, \n",
    "                               channel_shift_range=20, width_shift_range=0.1)\n",
    "batch_gen = gen.flow_from_directory(data_path+\"train\", batch_size=batch_size, target_size=(224, 224))\n",
    "val_batch_gen = gen.flow_from_directory(data_path+\"valid\", batch_size=batch_size, target_size=(224, 224))\n",
    "model = simple_conv(batch_gen, val_batch_gen)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "model.optimizer.lr = 1e-4\n",
    "model.fit_generator(batch_gen, batch_gen.samples//batch_size, epochs=12, validation_data=val_batch_gen, validation_steps=val_batch_gen.samples//batch_size)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 2 - Finetune VGG16"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "# config\n",
    "data_path = \"data/statefarm/\"\n",
    "sample_data_path = \"data/statefarm/sample/\"\n",
    "model_path = \"data/statefarm/models/\"\n",
    "target_size = (224,224)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "# load VGG\n",
    "from keras.applications.vgg16 import VGG16\n",
    "vgg = VGG16(include_top=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "# define a preprocessing function\n",
    "vgg_mean = np.array([123.68, 116.779, 103.939], dtype=np.float32).reshape((1,1,3))\n",
    "def vgg_preprocess(x):\n",
    "    x = x - vgg_mean\n",
    "    return x[:, ::-1] # reverse axis rgb->bgr"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "# test some data augmentation\n",
    "\n",
    "# gen = image.ImageDataGenerator(rotation_range=5, width_shift_range=0.05, height_shift_range=0.05, shear_range=3.14/8, zoom_range=0.1)\n",
    "# batch_gen = gen.flow_from_directory(sample_data_path+\"train\", batch_size=4, target_size=target_size, shuffle=False)\n",
    "# batch = batch_gen.next()[0]\n",
    "# plots(batch)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "/home/ubuntu/nbs\n",
      "Found 19093 images belonging to 10 classes.\n",
      "Found 3331 images belonging to 10 classes.\n"
     ]
    }
   ],
   "source": [
    "%cd ~/nbs\n",
    "# get augmented training data generator\n",
    "batch_size = 5 # use smaller batch size to lose fewer examples\n",
    "gen = image.ImageDataGenerator(preprocessing_function=vgg_preprocess, rotation_range=15, height_shift_range=0.05, \n",
    "                               shear_range=0.1, channel_shift_range=20, width_shift_range=0.1)\n",
    "batch_gen = gen.flow_from_directory(data_path+\"train\", batch_size=batch_size, target_size=target_size, shuffle=False)\n",
    "# get validation data generator\n",
    "val_batch_size = 2\n",
    "val_gen = image.ImageDataGenerator(preprocessing_function=vgg_preprocess)\n",
    "val_batch_gen = val_gen.flow_from_directory(data_path+\"valid\", batch_size=val_batch_size, target_size=target_size, shuffle=False)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "# precompute VGG outputs\n",
    "n_epochs = 5 # number of epochs of augmented data to generate\n",
    "vgg_output = vgg.predict_generator(batch_gen, 2, verbose=1)\n",
    "vgg_val_output = vgg.predict_generator(val_batch_gen, val_batch_gen.samples // val_batch_size, verbose=1)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "# save the VGG outputs\n",
    "\n",
    "# save_array(model_path+\"vgg_output.bc\", vgg_output)\n",
    "# save_array(model_path+\"vgg_val_output.bc\", vgg_val_output)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "# save the corresponding labels\n",
    "\n",
    "# labels = np.concatenate([batch_gen.classes for _ in range(n_epochs)])[:vgg_output.shape[0]]\n",
    "# val_labels = val_batch_gen.classes[:vgg_val_output.shape[0]]\n",
    "# save_array(data_path+\"raw/labels.bc\", labels)\n",
    "# save_array(data_path+\"raw/val_labels.bc\", val_labels)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "/home/ubuntu/nbs\n"
     ]
    }
   ],
   "source": [
    "# load precomputed vgg outputs\n",
    "%cd ~/nbs\n",
    "vgg_output = load_array(model_path+\"vgg_output.bc\")\n",
    "vgg_val_output = load_array(model_path+\"vgg_val_output.bc\")\n",
    "# load the corresponding labels\n",
    "labels = load_array(data_path+\"raw/labels.bc\")\n",
    "val_labels = load_array(data_path+\"raw/val_labels.bc\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(95457, 7, 7, 512)\n",
      "(3330, 7, 7, 512)\n",
      "(95457,)\n",
      "(3330,)\n"
     ]
    }
   ],
   "source": [
    "print(vgg_output.shape)\n",
    "print(vgg_val_output.shape)\n",
    "print(labels.shape)\n",
    "print(val_labels.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "# define a dense model \n",
    "model = Sequential([\n",
    "        Flatten(batch_input_shape=(None,7,7,512)),\n",
    "        Dropout(.8),\n",
    "        Dense(256, activation='relu'),\n",
    "        BatchNormalization(),\n",
    "        Dropout(.8),\n",
    "        Dense(256, activation='relu'),\n",
    "        BatchNormalization(),\n",
    "        Dropout(.8),\n",
    "        Dense(10, activation='softmax')])  \n",
    "model.compile(Adam(), loss='sparse_categorical_crossentropy', metrics=['accuracy'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "CALLBACKS = [CSVLogger(abspath(expanduser('~/nbs/data/statefarm/results.csv')), append=True)]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "batch_size = 256"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train on 95457 samples, validate on 3330 samples\n",
      "Epoch 1/1\n",
      "95457/95457 [==============================] - 60s - loss: 4.9691 - acc: 0.1043 - val_loss: 2.5609 - val_acc: 0.0925\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "<keras.callbacks.History at 0x7f5408eb1690>"
      ]
     },
     "execution_count": 13,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "K.set_value(model.optimizer.lr, 1e-5)\n",
    "model.fit(vgg_output, labels, batch_size=128, epochs=1, validation_data=(vgg_val_output, val_labels), callbacks=CALLBACKS)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train on 95457 samples, validate on 3330 samples\n",
      "Epoch 1/4\n",
      "95457/95457 [==============================] - 60s - loss: 2.0661 - acc: 0.3656 - val_loss: 0.9482 - val_acc: 0.7048\n",
      "Epoch 2/4\n",
      "95457/95457 [==============================] - 61s - loss: 0.9587 - acc: 0.6636 - val_loss: 0.7942 - val_acc: 0.7303\n",
      "Epoch 3/4\n",
      "95457/95457 [==============================] - 60s - loss: 0.6895 - acc: 0.7680 - val_loss: 0.7298 - val_acc: 0.7694\n",
      "Epoch 4/4\n",
      "95457/95457 [==============================] - 60s - loss: 0.5765 - acc: 0.8106 - val_loss: 0.7367 - val_acc: 0.7685\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "<keras.callbacks.History at 0x7f5408eb1890>"
      ]
     },
     "execution_count": 14,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "K.set_value(model.optimizer.lr, 1e-3)\n",
    "model.fit(vgg_output, labels, batch_size=128, epochs=4, validation_data=(vgg_val_output, val_labels), callbacks=CALLBACKS)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train on 95457 samples, validate on 3330 samples\n",
      "Epoch 1/4\n",
      "95457/95457 [==============================] - 55s - loss: 0.4839 - acc: 0.8433 - val_loss: 0.6763 - val_acc: 0.7781\n",
      "Epoch 2/4\n",
      "95457/95457 [==============================] - 55s - loss: 0.4346 - acc: 0.8597 - val_loss: 0.6958 - val_acc: 0.7694\n",
      "Epoch 3/4\n",
      "95457/95457 [==============================] - 55s - loss: 0.4017 - acc: 0.8714 - val_loss: 0.6930 - val_acc: 0.7784\n",
      "Epoch 4/4\n",
      "95457/95457 [==============================] - 55s - loss: 0.3799 - acc: 0.8806 - val_loss: 0.7303 - val_acc: 0.7661\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "<keras.callbacks.History at 0x7f542e6e8050>"
      ]
     },
     "execution_count": 15,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "K.set_value(model.optimizer.lr, 1e-3)\n",
    "model.fit(vgg_output, labels, batch_size=256, epochs=4, validation_data=(vgg_val_output, val_labels), callbacks=CALLBACKS)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train on 95457 samples, validate on 3330 samples\n",
      "Epoch 1/4\n",
      "95457/95457 [==============================] - 55s - loss: 0.3587 - acc: 0.8858 - val_loss: 0.7048 - val_acc: 0.7766\n",
      "Epoch 2/4\n",
      "95457/95457 [==============================] - 55s - loss: 0.3547 - acc: 0.8879 - val_loss: 0.7021 - val_acc: 0.7805\n",
      "Epoch 3/4\n",
      "95457/95457 [==============================] - 55s - loss: 0.3424 - acc: 0.8908 - val_loss: 0.7054 - val_acc: 0.7820\n",
      "Epoch 4/4\n",
      "95457/95457 [==============================] - 55s - loss: 0.3349 - acc: 0.8940 - val_loss: 0.7050 - val_acc: 0.7811\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "<keras.callbacks.History at 0x7f5408e52f50>"
      ]
     },
     "execution_count": 16,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "K.set_value(model.optimizer.lr, 1e-4)\n",
    "model.fit(vgg_output, labels, batch_size=256, epochs=4, validation_data=(vgg_val_output, val_labels), callbacks=CALLBACKS)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "model.save_weights(model_path+\"dense.h5\")"
   ]
  }
 ],
 "metadata": {
  "anaconda-cloud": {},
  "kernelspec": {
   "display_name": "Python [conda root]",
   "language": "python",
   "name": "conda-root-py"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 2
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython2",
   "version": "2.7.12"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
